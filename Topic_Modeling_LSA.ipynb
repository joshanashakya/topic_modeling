{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f705b5",
   "metadata": {},
   "source": [
    "### 1. Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63b74b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2884ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digital Music data (64,706) downloaded from: http://jmcauley.ucsd.edu/data/amazon/ \n",
    "json_objs = []\n",
    "with open(\"Digital_Music_5.json\", \"r\") as f:\n",
    "    for json_obj in f:\n",
    "        json_objs.append(json.loads(json_obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d2e8024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3EBHHCZO6V2A4</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Amaranth \"music fan\"</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>It's hard to believe \"Memory of Trees\" came ou...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Enya's last great album</td>\n",
       "      <td>1158019200</td>\n",
       "      <td>09 12, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZPWAXJG9OJXV</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>bethtexas</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>A clasically-styled and introverted album, Mem...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Enya at her most elegant</td>\n",
       "      <td>991526400</td>\n",
       "      <td>06 3, 2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A38IRL0X2T4DPF</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>bob turnley</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>I never thought Enya would reach the sublime h...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The best so far</td>\n",
       "      <td>1058140800</td>\n",
       "      <td>07 14, 2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A22IK3I6U76GX0</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Calle</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>This is the third review of an irish album I w...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Ireland produces good music.</td>\n",
       "      <td>957312000</td>\n",
       "      <td>05 3, 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1AISPOIIHTHXX</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Cloud \"...\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Enya, despite being a successful recording art...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5; music to dream to</td>\n",
       "      <td>1200528000</td>\n",
       "      <td>01 17, 2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin          reviewerName helpful  \\\n",
       "0  A3EBHHCZO6V2A4  5555991584  Amaranth \"music fan\"  [3, 3]   \n",
       "1   AZPWAXJG9OJXV  5555991584             bethtexas  [0, 0]   \n",
       "2  A38IRL0X2T4DPF  5555991584           bob turnley  [2, 2]   \n",
       "3  A22IK3I6U76GX0  5555991584                 Calle  [1, 1]   \n",
       "4  A1AISPOIIHTHXX  5555991584           Cloud \"...\"  [1, 1]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  It's hard to believe \"Memory of Trees\" came ou...      5.0   \n",
       "1  A clasically-styled and introverted album, Mem...      5.0   \n",
       "2  I never thought Enya would reach the sublime h...      5.0   \n",
       "3  This is the third review of an irish album I w...      5.0   \n",
       "4  Enya, despite being a successful recording art...      4.0   \n",
       "\n",
       "                        summary  unixReviewTime   reviewTime  \n",
       "0       Enya's last great album      1158019200  09 12, 2006  \n",
       "1      Enya at her most elegant       991526400   06 3, 2001  \n",
       "2               The best so far      1058140800  07 14, 2003  \n",
       "3  Ireland produces good music.       957312000   05 3, 2000  \n",
       "4        4.5; music to dream to      1200528000  01 17, 2008  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(json_objs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd52cc2",
   "metadata": {},
   "source": [
    "### 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b75f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b823187",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = stopwords.words(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# noun and adjectives\n",
    "chosen_tags = [\"NN\", \"NNS\", \"JJ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cbab38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    # remove punctuation\n",
    "    nopunc_text = re.sub(r\"[!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~]\", \" \", text)\n",
    "    # remove everything except alphabetic characters\n",
    "    alpha_text = re.sub(r\"[^A-Za-z]\", \" \", nopunc_text)\n",
    "    # eliminate multiple spaces\n",
    "    nomspace_text = re.sub(r\"\\s+\", \" \", alpha_text)\n",
    "    return nomspace_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb1eb7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_tag(tag):\n",
    "    if tag.startswith(\"N\") or tag.startswith(\"J\"):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith(\"V\"):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith(\"R\"):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e9daece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # clean text\n",
    "    cleaned_text = clean(text)\n",
    "    lowered_text = cleaned_text.lower()\n",
    "    \n",
    "    # tokenization\n",
    "    tokens = word_tokenize(lowered_text)\n",
    "    \n",
    "    # remove stopwords and single character words\n",
    "    words = [token for token in tokens if token not in stoplist or len(token) > 1]\n",
    "    \n",
    "    # lemmatize words\n",
    "    tagged_words = nltk.pos_tag(words)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, get_pos_tag(tag)) for word, tag in tagged_words if tag in chosen_tags]\n",
    "    \n",
    "    return \" \".join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87cb9ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df[\"reviewText\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82cf1c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    hard memory tree year passage time last great ...\n",
       "1    album memory tree subtlety many song shyness s...\n",
       "2    sublime height evacuee marble hall shepherd mo...\n",
       "3    third review irish album write today others cr...\n",
       "4    successful artist doesn broad appeal other art...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a84458b",
   "metadata": {},
   "source": [
    "### 3. Topic modeling using LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54c2eed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec727dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bag_of_words = vectorizer.fit_transform(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cd3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components = 10)\n",
    "lsa = svd.fit_transform(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c6c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_encoded_df = pd.DataFrame(lsa, columns = [\"topic1\", \"topic2\", \"topic3\", \"topic4\", \"topic5\", \"topic6\", \"topic7\", \"topic8\", \"topic9\", \"topic10\"])\n",
    "topic_encoded_df[\"body\"] = df_clean\n",
    "display(topic_encoded_df[[\"body\", \"topic1\", \"topic2\", \"topic3\", \"topic4\", \"topic5\", \"topic6\", \"topic7\", \"topic8\", \"topic9\", \"topic10\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2859015",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = vectorizer.get_feature_names()\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69af6a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_matrix = pd.DataFrame(svd.components_, index = [\"topic1\", \"topic2\", \"topic3\", \"topic4\", \"topic5\", \"topic6\", \"topic7\", \"topic8\", \"topic9\", \"topic10\"], columns = dictionary).T\n",
    "encoding_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2074bb2c",
   "metadata": {},
   "source": [
    "### 6. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e30565a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
